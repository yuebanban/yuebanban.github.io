# 4. A Survey on Dialogue Systems: Recent Advances and New Frontiers----阅读笔记

## 1.Introduction

将对话系统分为两个种类：task-oriented 以及 non-task-oriented。传统的task-oritented的对话系统首先是理解一个人提出的问题，然后再根据预先设定好的规则来判断应该给出怎样的回答。一般的规则制定是根据费力的特征工程或者认为制定而来，这样的方式费时费力，因此近年来随着深度学习的发展，深度学习使得高维度的特征工程成为可能，同时也能够建立端到端的系统。关于non-task-oritened的对话系统，一般有两种方式：一是使用序列到序列的生成式模型，另一种是使用选择搜索的方式。

## 2. task-oriented 对话系统

task-oriented 对话系统包括四个步骤：自然语言理解（NLU），状态跟踪（State Traker），对话策略（Dialog Policy），自然语言生成（NLG）

语句理解：将语言进行理解，包括语言意图，以及词语语义记录。intent detection：将语言的意图进行归类；slot filling：序列标记问题，将每个单词所对应的语义进行标记。

状态跟踪：主要是将多轮历史对话进行总结，理解上下文的含义。

对话策略：对话策略是跟根据状态选择下一步需要做什么行动。

自然语言生成：负责把上一步产生的策略转换成自然语言输出。

端到端的学习方式：传统的这种对话系统有两个缺陷：1.终端用户的反馈很难直接体现在整个对话系统中；2.每个组件的相互依赖，因此生成了端到端的系统，在端到端的系统中，首当其冲的问题是，数据库的衔接不可微分。这是因为数据库需要通过 symbolic query 来进行检索，而一般的 RNN 在中间层不提供 symbolic representation。

关于数据库的问题，有以下解决思路：第一种方法是把数据库的操作 action 变成 dialog policy 的一部分。然后通过 supervised learning 或者 reinforcement learning 进行学习 。这种方法的好处是可以适用于任何数据库或者 API，但是缺点是不能很好的 handle 用户输入的 uncertainty，因为每次搜索只能搜索一种最有可能的 query。

第二种方法是假设系统可以看到整个 database 的每一行，然后通过用户目前给出条件的概率，来计算出数据库每一行符合用户条件的概率分布 [3]。 这样做对于使用第三方 API 的开发者来说不是一个好消息。另外，当数据库很大时，概率分布的计算需要很大的计算量。

第三种方法是利用 RNN decoder 直接生成数据库的 query [4]. 这种做法非常有前途。

## 3. 非目标式的对话

非目标式的对话其实就是闲聊，一般这种对话方式有两种解决思路：一种是生成式对话，一种是根据已有的句子进行挑选的对话。

### 3.1 生成式对话系统

在生成式对话系统中，受到机器翻译的启发，很多研究者使用Seq2Seq的模型进行训练，尽管对话系统于机器翻译相比，在语句对齐以及回答的多样性上都有差异，但是通过对Seq2Seq模型的各种改进，在对话系统上已经有很不错的结果。

Seq2Seq模型包括一个encoder和decoder，概略来讲，encoder将输入通过RNN来获取一个context向量，然后decoder通过这个context生成回答，其中还可以使用attention机制来获取context向量。

#### 上下文

在对话系统中，上下文的信息对于生成有意义，多样性的回答是非常关键的，因此，在各个研究中的seq2seq模型中，会使用多层级的模型来得到context模型。

#### 回复的多样性

由于使用最大似然函数作为生成语句的评估函数，使得对话系统很容易生成“我不知道”，“我很好”这样没有意义的回答，因此增加回复语句的多样性就是非常关键的。一种比较好的方法就是寻找其他更加合适的目标函数来进行训练，例如考虑互信息，IDF等项；另外的方式是对进行语句选择时对候选语句的选择进行改进；还有研究者使用加入随机因变量来增加回复的多样性。

#### 主题性和一致性

对话是存在一定的背景的，同时对话也是

#### 外部知识扩充

使用Memory network

#### 交互性对话学习

这里我理解的就是使用强化学习的方法来训练对话系统

#### 评估

对回复的评价是对话系统训练设计的非常重要的步骤，这个评估函数于目标函数不一定是一样的。

### 3.3 搜索式对话系统

这种对话系统是从已有的回复中进行搜索答案，最主要的就是match算法的设计。

